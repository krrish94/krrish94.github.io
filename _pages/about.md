---
layout: about
title: about
permalink: /
subtitle: Multimodal Generative World Models
profile_pic: prof_pic.png
cv: CV.pdf
thesis: thesis_krishna.pdf
google_scholar: https://scholar.google.co.uk/citations?user=kcr8134AAAAJ
linkedin: https://www.linkedin.com/in/krrish94/
github: https://github.com/krrish94

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am a postdoc at [MIT CSAIL](https://www.csail.mit.edu/) with [Josh Tenenbaum](http://web.mit.edu/cocosci/josh.html) and [Antonio Torralba](https://web.mit.edu/torralba/www/). I received my PhD at [Mila](https://mila.quebec/en/), advised by [Liam Paull](http://liampaull.ca/).

My goal is to design intelligent agents that build rich, multisensory models of the world, integrating vision, audition, haptics, and language. My research revolves around two questions: *What kinds of computational models of the world do robots and AI systems need? How do we build them?* My work draws upon ideas from robotics, computer vision, graphics, and computational cognitive science; intertwining our understanding of the world with probabilistic inference and deep learning.

My work has been recognized with PhD fellowship awards from NVIDIA and Google, and a best-paper award from IEEE RAL.

<span style="color:red; font-weight:bold;">I am on the faculty job market this season.</span>
