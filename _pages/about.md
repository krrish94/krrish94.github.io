---
layout: about
title: about
permalink: /
subtitle: Inverting world models for perception, reasoning, and action
profile_pic: prof_pic.png
cv: CV.pdf
thesis: thesis_krishna.pdf
google_scholar: https://scholar.google.co.uk/citations?user=kcr8134AAAAJ
linkedin: https://www.linkedin.com/in/krrish94/
github: https://github.com/krrish94

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am a postdoc at [MIT CSAIL](https://www.csail.mit.edu/) with [Josh Tenenbaum](http://web.mit.edu/cocosci/josh.html) and [Antonio Torralba](https://web.mit.edu/torralba/www/). I received my PhD at [Mila](https://mila.quebec/en/), advised by [Liam Paull](http://liampaull.ca/).

My goal is to design intelligent agents that build rich, multisensory models of the world, integrating vision, audition, tactile perception (and more recently, language). I am particularly interested in *invertible world models* that bridge real-world perception and action. This is seemingly trivial for humans, but currently impossible for AI systems. My research takes steps to bridge this gap by drawing ideas from robotics, computer vision, graphics, and computational cognitive science; intertwining our understanding of the world with probabilistic inference and deep learning.

My work has been recognized with PhD fellowship awards from NVIDIA and Google, and a best-paper award from IEEE RAL.
